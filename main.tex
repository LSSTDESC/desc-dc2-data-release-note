\PassOptionsToPackage{usenames,dvipsnames}{xcolor}
\documentclass[modern]{descnote}
\pdfoutput=1 %for arXiv submission
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage[utf8]{inputenc}
\usepackage{newtxtext,newtxmath}
\usepackage[english]{babel}
\usepackage{amsmath,amstext}
\usepackage[figure,figure*]{hypcap}
\usepackage{threeparttablex}
\usepackage{longtable}
\usepackage{inconsolata}

\definecolor{DESCred}{rgb}{0.63,0.00,0.20}
\hypersetup{colorlinks=true,breaklinks=true,
  citecolor=DESCred,filecolor=DESCred,linkcolor=DESCred,urlcolor=DESCred}

%figure pathhttps://www.overleaf.com/project/5fc85a437ab1bf2161bc7294
\graphicspath{{figs/}}

% for \autoref
\renewcommand*\sectionautorefname{Section}
\renewcommand*\subsectionautorefname{Section}
\renewcommand*\subsubsectionautorefname{Section}

%%%%% Custom commands %%%%%%

% For creating hyperlinks
\newcommand*{\https}[1]{\href{https://#1}{\nolinkurl{#1}}}
\newcommand*{\http}[1]{\href{http://#1}{\nolinkurl{#1}}}

% Other useful commands
\DeclareUrlCommand\code{\urlstyle{tt}}

% Commands for editing and revisions
\newcommand{\todo}[1]{\textcolor{orange}{#1}}


%%%%% Front Matter %%%%%%

\shorttitle{DESC DC2 Data Release Note}
\shortauthors{LSST~DESC}

\begin{document}
\title{DESC DC2 Data Release Note}
\input{authors}

\begin{abstract}
%\clearpage
%
To prepare for the analysis of the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST), the LSST Dark Energy Science Collaboration (LSST DESC) undertook a series of large-scale simulation and analysis exercises.
The second of these, called Data Challenge 2 (DC2), simulated 300~deg$^2$ in the $ugrizy$ LSST filters following the first five years of a reference LSST observing cadence.
DESC then processed these images with the current state of the LSST Science Pipelines.
We here make available the processed object catalogs from this effort.
We provide a web portal connected to Globus data services to enable convenient access to the data products.
This Note provides a brief description of the major features of the available data sets, a description of data access, a detailed tutorial access and use the data, and two example Python Jupyter Notebooks to help users get started interacting with and analyzing the data.
We welcome feedback about this data release and encourage questions posted to the GitHub repository for this release.
%

%We have recently created a simulated sky survey in order to prepare for the analysis of the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST) by the LSST Dark Energy Science Collaboration (LSST DESC). In this Note, we describe the accompanying public data release of the  
%data products for the LSST DESC second data challenge (DC2). The simulated DC2 sky survey covers an area of approximately 300~deg$^2$ in six optical bands over a five year observing period. We provide a brief description of the major features of the available data sets. In order to enable convenient access to the data products, we have developed a web portal connected to Globus data services. The Note provides a description of data access as well as a reference to detailed instructions and,  additionally, two example Python Jupyter Notebooks to aid first interactions with the data. We welcome feedback and questions about the data release via a Github repository.

\clearpage
\end{abstract}

\tableofcontents

\clearpage

\section{Introduction}

In the next decade, an unprecedented survey of the sky will be carried out using the Vera C. Rubin Observatory, the Legacy Survey of Space and Time \citep{2009arXiv0912.0201L,2019ApJ...873..111I}. One of the major aims of the survey is to unravel the origin of the cause of the accelerated expansion of the Universe. The LSST Dark Energy Science Collaboration (DESC)\footnote{\https{lsstdesc.org}} was formed to carry out this exciting endeavor~\citep{Abate:2012za}. In order to prepare for the arrival of data, LSST DESC has generated two data challenges, DC1 and DC2, using sophisticated cosmological and  image simulations. The data challenges have been designed to mimic actual data from the Rubin Observatory in small, representative areas of the LSST observing footprint.

Both LSST DESC data challenges are based on realistic simulations of the extragalactic sky and employ a comprehensive image simulation library with a range of features, imSim. The resulting synthetic data were processed with Rubin's LSST Science Pipelines~\citep{2017ASPC..512..279J} to generate the final data products. The first data challenge, DC1, covers a $\sim$40 deg$^2$ area and ten years of observations. The image simulations were carried out for $r$-band only. A detailed description and a range of analysis results are provided in~\cite{dc1}.  In this data release note, we focus on the second data challenge, DC2. A comprehensive description of the LSST DESC DC2 Simulated Sky Survey can be found in~\cite{2020arXiv201005926L}. DC2 covers $\sim$300 deg$^2$ in the wide-fast-deep (WFD) area to be surveyed by LSST. Within this area, a small 1~deg$^2$ deep-drilling field (DDF) has been simulated as well. For the data release described in this note, only data from the WFD campaign and 5 years of observations are provided, corresponding to the planned sixth Rubin data release, DR6. For DC2, all six optical bands $ugrizy$ are included in the image simulations. The simulations, both for the extragalactic catalog and image generation, have many features that are relevant and realistic. However, given the complexity of the actual data and finite resources available, some features are less realistic or simply omitted. \cite{2020arXiv201005926L} provide a comprehensive discussion about the DC2 design choices that have been guided mostly by considerations regarding cosmological probes.  

For LSST DESC, the data challenges serve multiple purposes. The advantage of simulated data is that the underlying truth is known. Therefore, even if they are not as complex as observational data or have different systematics, they provide an excellent testbed for DESC analysis pipelines. Given that the data formats closely mimic the Rubin data products, they also serve to aid the development and optimization of data access methods. The data challenges also offer the opportunity to exercise the LSST Science Pipelines and investigate their performance, in particular with regard to how systematic effects in the data are handled. By making a first set of the data products publicly available, we hope that other LSST Science Collaborations will be able to carry out useful tests as part of preparations for data arrival preparation as well. In addition, the data should be of value for the broader optical astronomy and cosmology community.

This note is organized as follows. In~\autoref{sec:features} we describe the major features of the DC2 data set. We provide an overview of the data products that are part of this release in~\autoref{sec:products}. We provide instructions for data access, including a set of example Python Jupyter notebooks, in~\autoref{sec:access}. We conclude in~\autoref{sec:outlook} and provide a brief description of possible future data releases. 

\section{Major Features of the Data Set}
\label{sec:features}

\subsection{Astrophysics Inputs}

The astrophysical components of this data set are mostly limited to the types of objects needed to support static probes of dark energy science, specifically the galaxies from the cosmoDC2 extragalactic catalog \citep{korytov}.  In addition, this data set includes stars from a simulated Milky Way, which are needed for the astrometric and photometric calibration by the image processing pipeline, as well as Type Ia supernovae, which were included throughout the 300~deg$^2$ DC2 region.

As noted, the galaxies are from the cosmoDC2 extragalactic catalog\footnote{Available at \https{portal.nersc.gov/project/lsst/cosmoDC2/}}, which covers 440 deg$^2$ out to a redshift of $z = 3$ and is complete to $m_r <28$.  The cosmoDC2 catalog is based on the Outer Rim $N$-body simulation \citep{2019ApJS..245...16H}, and the properties of the galaxies were derived using the Galacticus semi-analytic model \citep{benson_2010b} and painted onto dark matter halos using GalSampler \citep{2020MNRAS.495.5040H}.  The derived galaxy properties include stellar mass, morphology, spectral energy distributions, broadband filter magnitudes, host halo information, and weak lensing shears.   The bulge and disk components of the galaxies are rendered separately as S\'ersic profiles, and galaxies with $m_i > 27$ have ``knots'' of star formation added in order to model more complex light profiles for the fainter galaxies. The fluxes for these star-forming regions have been re-allocated from the disk component, and the knots have the same spectral energy distribution (SED) as the disk.

The Milky Way stars are simulated using the Galfast model of \citet{2008ApJ...673..864J}, which is based on densities and colors of sources in the Sloan Digital Sky Survey (SDSS). Stellar variability is included for periodic objects (e.g., RR Lyrae and Cepheids) and for non-periodic variables (e.g., CVs, flaring M-dwarfs, etc.).  Stars without a definitive variability class are modeled based on the Kepler Q17 data release \citep{2016ksci.rept....3T}.  The Galactic reddening is based on the three-dimensional model of \cite{2005AJ....130..659A}.

Finally, Type Ia supernovae have been added throughout the DC2 region out to a redshift of $z=1.4$ with a population density that is consistent with observations.

\subsection{Image Simulation Features}

DC2 used the \code{minion_1016} observing cadence\footnote{Available at \https{docushare.lsst.org/docushare/dsweb/View/Collection-4604}}, which was the Rubin Observatory LSST baseline cadence at start of the DC2 simulations. This cadence provides the nominal field positions, telescope rotations, and filter selections for each 30-second pointing, as well as predicted seeing, airmass, and sky background components.  We have added random translational and rotational dithering to the nominal pointings in order to make the sky coverage more uniform.

The imSim simulation software uses the GalSim package \citep{2015A&C....10..121R} to render the astrophysical objects and the night sky.  The point-spread functions (PSFs) for each exposure are computed using a set of atmospheric phase screens that are realizations of Gaussian random fields with a Von Karman power spectrum.  In addition, the PSF calculation includes an optical model of the telescope based on modeling of the active optics system for Rubin Observatory.  After convolution with the PSF, objects are rendered on the LSST CCDs taking into account the instrumental throughput in each band, the object's SED shape within the bandpass, atmospheric effects such as differential chromatic refraction, and the convergence of the incident beam from the telescope optics. GalSim's sensor model includes the brighter-fatter and tree-ring electrostatic effects that are present in the CCDs used in the LSST Camera (LSSTCam).  Finally, electronics readout effects such as bleed trails, CCD segmentation, intra-CCD cross-talk, read noise, etc., are applied.  These effects are based on measurements of the actual LSSTCam hardware.


\section{Available Data Sets}
\label{sec:products}

This Data Release (v1) provides the data from the WFD campaign for 5 years of observations (corresponding to Rubin's DR6). This data set includes two ``Tables'': the ``Object Table'' and the ``Truth-match Table.'' We define these tables and describe their data models in the subsections below. 

\subsection{Object Table}
\label{sec:object}

The Object Table contains information about static astronomical objects measured on a stacked (coadd) image. The photometry in the Object Table is measured with the forced photometry method, i.e., it is consistently measured across multiple bands using a fixed position, which is determined from the reference band for each source \citep[Sec.~3.4 of][]{10.1093/pasj/psx080}. 

The generation of the Object Table is described in detail in \S~8 of \cite{2020arXiv201005926L}. In short, after the LSST Science Pipelines (v19) produce the deepCoadd catalogs of multiple bands, we merge these catalogs across bands, and apply certain column renaming and translations to produce the final Object Table. The renaming and translations are meant to produce a science-ready catalog that resembles the Rubin LSST Data Products Definition Document (LSE-163; \https{lse-163.lsst.io}) for the end users. 

Each entry (row) in the Object Table corresponds to one measured astronomical object, assigned with a unique ID (\code{objectID}). There are no duplicated entries in the Object Table. For details about the physical representation of the Object Table, see \autoref{sec:representation}. The full schema for the Object Table can be found in \autoref{app:object-schema}. 

\subsection{Truth-match Table}
\label{sec:truth}

The Truth-match Table is a joint representation of both the truth information (i.e., the measurable fluxes and positions of astronomical objects that serve as input values to the image simulations) and their best matches to the measured objects in the Object Table. The Truth-match Table allows users to examine, for example, the differences between true and measured fluxes and positions, and compare to the expected levels of photometric and astrometric accuracy and precision.

The generation of the Truth-match Table is described in \S\,4.2.1 of \cite{2020arXiv201005926L}. The truth information in the Truth-match Table only includes ``summary'' properties (i.e., static, or infinite-time averaged fluxes) of galaxies (including infinite-time averaged AGN components \todo{check with Joanne}), stars, and supernovae (SNe). Time-varying properties are not included. The match information stored in the  Truth-match Table is produced with the following procedure applied for each entry in the Object Table:
\begin{enumerate}
    \item Search for all truth entries that are within 1~arcsec and have a $r$-band magnitude difference ($\Delta r$) less than 1~mag. If one or more truth entries satisfying these criteria are found, pick the truth entry with the smallest $|\Delta r|$ as the match, and set \code{is_good_match} to True.
    \item If no truth entry was found in Step (1), pick the truth entry that is the nearest neighbor of the object entry on sky as the match, and set \code{is_good_match} to False.
\end{enumerate}
Given this procedure, every entry in the Object Table is assigned exactly one match. The majority of object entries have a ``good'' match (i.e., satisfying criteria in Step 1 above), and the rest have a nearest-neighbor match. More than 90\% of the ``good'' matches are not only the closest match in magnitude, but also the nearest neighbor match. 
Note that this matching procedure is applied to each tract individually; hence, a tiny fraction ($<0.002\%$) of objects may not have good matches due to being too close to the tract boundaries. 

Because the Object Table was used as the reference catalog for the matching procedure, some truth entries may be chosen as a match more than once, while others may not be chosen at all.
Flags to distinguish these situations are included in the Truth-match Table. 
Selecting all entries with \code{match_objectId} $> -1$ from the Truth-match Table would result in a subset of Truth-match entries that have exactly the same row order as the entries in the Object Table (and hence may contain duplicated truth entries). On the other hand, selecting all entries with \code{is_unique_truth_entry} being True would produce a subset of Truth-match entries that contains all unique truth entries, including truth entries that have not been chosen as a match.
These selections are particularly important for users who wish to access the files directly. For users who use GCRCatalogs (\autoref{sec:gcr}), the reader will automatically select the correct rows depending on whether you are loading the Truth Table or the Match Table (see \autoref{sec:notebooks} for examples).
https://www.overleaf.com/project/5fc85a437ab1bf2161bc7294
The physical representation of the Truth-match Table is described in \autoref{sec:representation}. The full schema for the Truth-match Table can be found in \autoref{app:truth-schema}.



\section{Data Access}
\label{sec:access}


\subsection{Physical Representation of the Data Sets}
\label{sec:representation}

All data tables in this release are stored in the Apache Parquet\footnote{\https{parquet.apache.org}} format, an efficient columnar storage form, with I/O tools readily available for multiple development systems. 
The data files can be easily downloaded to the user's machine via Globus (\autoref{sec:download}), and read with Python packages such as \code{pyarrow} or \code{fastparquet}.
We additionally provide a Python package, \code{GCRCatalogs}, which contains a high-level user API to access the data files (\autoref{sec:gcr}). 

Each data table is further partitioned into several files that correspond to different parts of the sky. The partition is based on the ``tract'' value in the ``Rings sky map'' pixelization of LSST Science Pipelines.\footnote{\https{pipelines.lsst.io/py-api/lsst.skymap.ringsSkyMap.RingsSkyMap.html}} \autoref{fig:skymap} shows a visual representation of the partition. The same partition is used for both Object Table and Truth-match Table. No padding is included; i.e., an entry that is near the tract boundary still only appears in the tract it belongs to. Each Parquet file contains only one partition (row group). 

\begin{figure}[tbh!]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/skymap.png}
    \caption{Sky map of the DC2 footprint. The large green trapezoid is the full DC2 footprint. The small red rectangle in the upper right corner is the DDF region that is excluded in this release. Each tract is represented by a rectangle with a number on it showing the tract ID. The light pink region shows the size of Rubin focal plane as a comparison.}
    \label{fig:skymap}
\end{figure}



\subsection{Downloading Data Files}
\label{sec:download}

The data files are made available via a Globus\footnote{\https{www.globus.org}} endpoint. Any user with a Globus ID can initiate transfers of the full or partial data set to another endpoint to which the user has access, should it be a laptop or a high-performance computing center. 

Please visit our data portal\footnote{\https{lsstdesc-portal.nersc.gov}} to initiate data transfers. Detailed instructions can be found in our Public Release repository.\footnote{\https{github.com/LSSTDESC/DC2-Public-Release}\label{fn:repo}}

\subsection{Accessing Data in Python}
\label{sec:gcr}

While the data files are accessible via standard Parquet IO tools, we provide a high-level Python package, \code{GCRCatalogs}, to assist users to access DC2 data. 

The \code{GCRCatalogs} package is installable by package managers \code{pip} and \code{conda}.
Once installed, the package should be configured to recognize the path to which the data files have been downloaded. The DC2 data set will then be readily available in the user's own Python environment. 
Detailed instructions can be found in our Public Release repository (see Footnote~\ref{fn:repo}).


\subsection{Example Python Jupyter Notebook}
\label{sec:notebooks}

We provide two example Python Jupyter Notebooks which demonstrate how to use \code{GCRCatalogs} to access the data, to explain the data model, and to show a few simple analyses that can be used as starting points for further development. 
These Jupyter Notebooks can be found in the associated GitHub repository (see Footnote~\ref{fn:repo}).

\section{Conclusion and Outlook}
\label{sec:outlook}
In this note we described the first public data release for DC2 carried out by the LSST DESC. We make data available for a simulated WFD survey spanning 300 degree$^2$ and 5 years of Rubin observations, including a subset of the coadd-based catalogs that would be included in Rubin Observatory's DR6. We provided a brief overview of the major features of the data set in~\autoref{sec:features} and a detailed description of the available products in~\autoref{sec:products}. The data can be accessed via a web portal that offers a convenient interface for data transfers using Globus, and we also release a set of example notebooks to enable first quick experiments, as described in~\autoref{sec:access}. We encourage new users to provide feedback and ask questions via a dedicated GitHub repository (see Footnote~\ref{fn:repo}).

This Data Release (v1) focuses on a limited set of data products generated with the LSST Science Pipelines. In the future, we plan to extend this data release in several directions. First, LSST DESC is currently working on generating so-called ``add-on'' catalogs. These catalogs provide additional information obtained from further processing the data. Examples include a photo-z catalog and a cluster catalog. Once these catalogs have been carefully validated and are of sufficient quality to be of broader interest, they will be added to the DC2 Data Release. Second, the processing of the DDF portion of DC2 is still in progress. As explained in more detail in~\cite{2020arXiv201005926L}, the DDF region contains several astrophysical components, e.g.~AGNs, that are not available in the WFD region. As with the add-on catalogs, once careful validation has concluded, we plan to make those data available as well. Finally, for cosmology it is very informative to compare results from different data releases to build a better understanding of the impact of the depth of the data on cosmological constraints. Therefore, LSST DESC is currently generating additional coadds and associated catalogs for subsets of the data corresponding to 1- and 2-year depth. Depending on the feedback we receive, these datasets will become part of future public data releases as well.


%%%%%% Appendices %%%%%% 
\clearpage
\appendix
\section{Changelog}
\input{tables/changelog}

\clearpage

\section{Table Schema}

\subsection{Object Table Schema}
\label{app:object-schema}
\input{tables/schema_object}

\bigskip

\subsection{Truth-match Table Schema}
\label{app:truth-schema}
\input{tables/schema_truth}


%%%%%% Acknowledgments %%%%%% 
\clearpage
\section*{Acknowledgments}
\phantomsection
\addcontentsline{toc}{section}{Acknowledgements}

\input{desc_ack_standard.tex}

% Individual acknowledgments (sorted by author order)
The work of SH, APH, KH, JH, EK, DK, PL, TU and ASV at Argonne National Laboratory was supported under the U.S. DOE contract DE-AC02-06CH11357.
Support for YYM was provided by NASA through the NASA Hubble Fellowship grant no.\ HST-HF2-51441.001 awarded by the Space Telescope Science Institute, which is operated by the Association of Universities for Research in Astronomy, Incorporated, under NASA contract NAS5-26555. 

% Contribution statements

%% The contributions from the authors are listed below in alphabetical order.
BA investigated variations in the sky model across the focal plane in imSim.
%
HA implemented the dithers and extracted the visit lists for the simulations.
%
YNB worked on the design and implementation of the imSim workflow and developed extensions to Parsl to meet the performance and scalability needs of the imSim workflow.
%
FEB contributed to the development and testing of the AGN model.
%
GB managed the European computational grid work for DC2.
%
RB conceptualized the interaction of Time Domain Science implementations with existing middleware software, compiled scientific desiderata for SN group, developed the implemented the code and the SN population along with their assignment to cosmoDC2 host galaxies, the cadence selection and contributed to the validation of SN, the planning and requirements for strong lensing injection, helped with validation of SN done by JWP, DS, RH, and SJ.
%
JRB contributed to production of the truth catalogs and to the software package GCRCatalogs.
%
DB contributed to the the image processing pipeline configuration, deployment and tuning at CC-IN2P3 and to the validation of the various data products.
% 
KC contributed to the simulation and data processing workflows and Globus distribution portal.
%
JC worked on imSim development, image validation, image processing development and debugging, and calibration product generation.
%
JCT was responsible for the definition, implementation, and deployment of the SRS pipeline at CC-IN2P3.
%
AJC led the development of the LSST simulation tools and contributed to the initial definition of the DESC data challenges.
%
ADW developed the LSST DESC exposure checker and organized the DC2 visual inspection effort.
%
RD assisted in organization, planning and obtaining computing resources.
%
SFD helped design and implement the stellar and AGN variability models. He also implemented and maintained the interface between the cosmoDC2 simulations, the GalFast simulations, and ImSim.
%
SWD edited the note text.
%
EG contributed to the field location and dither design.
%
TG worked on the production of certain calibration products, and assisted with management of DESC NERSC resources.
%
SH is the HACC team lead; he contributed to the assessment of image generation computational requirements, co-led the management of DESC NERSC resources.
%
APH helped design and build the model of the galaxy-halo connection used to generate the cosmoDC2 extragalactic catalog. 
%
KH was responsible for the overall organization of the DC2 project, was involved in many aspects of the extragalactic catalog production, and contributed to the text of the note.
%
FH implemented the mechanism for making the LSST Science Pipelines available online and usable both at CC-IN2P3 and at NERSC, managed the CC-IN2P3 data processing infrastructure used by the image processing pipeline and was responsible for the prompt data transfer between CC-IN2P3 and NERSC.
%
RH worked on the coordination and testing of simulated SN inside DC2, draft reading and editing.
%
JH was a core member of the extragalactic catalog production team.
%
MJ contributed significant portions of code to both the GalSim and ImSim code bases for the purposes of generating the DC2 images.  He also contributed to the simulation design, especially decisions about which features should be included to achieve the desired goals of realism in the galaxy shapes for weak lensing science, while maintaining computational feasibility.
%
JBK was the main developer of the SL Sprinkler that inserted strongly lensed AGN into the instance catalogs and contributed the text of the paper relating to the SL Sprinkler.
%
HMK co-chaired the DM-DC2 task force which coordinated the DESC DM processing of the DC2 image simulation data, produced required calibration products, and managed the DESC software and data resources at NERSC.
%
EK was one of the principal developers of the extragalactic catalog that was used as input to the image simulations and also worked on the validation of the DC2 object catalogs, as described in the DC2 survey paper.
%
DK led the development of the model underlying the extragalactic catalog.
%
KSK contributed to the conceptual design of the simulated survey including determining which electronic effects to simulate and by association which master calibration products to include.
%
FL contributed the model for the knots component included in galaxy light profiles, and the implementation of said model in CatSim and imSim.
%
PL made significant contributions to the development of the cosmodc2 extragalactic catalog
%
CSL helped develop physical models of the CCD detectors, which allowed physically real simulations of tree rings and the brighter-fatter effect.
%
NL contributed to the generation of strongly lensed host galaxies of multiply lensed AGN and SNIa in the strong lensing systems sprinkled in the DDF.
%
EPL made contributions to the sky model in imSim. 
%
RHL contributed to the validation of the final data catalogs and provided support in using the LSST Science Pipelines.
%
RM organized analysis teams and synthesized input that factored into the overall DC2 design and validation, was engaged in the validation efforts, and edited the note text. 
%
YYM contributed to the generation, validation, and access of various DC2 data products, the preparation of public release, and text of this note.
%
PJM helped design the survey regions and cadences, provided high-level scientific oversight, and contributed to defining the strong lensing requirements.
%
JEM helped develop and validate the PSF simulation within imSim.
%
JWP contributed to the generation and documentation for the truth tables of strongly lensed SNe and AGN for the full DC2 effort.
%
JP contributes to write notebooks using Apache Spark to access and manipulate the DC2 data.
%
DJP implemented a model for LSST optical effects in imSim, assisted in the development of internal data access tools, and contributed to the visual validation of DC2 images.
%
JP implemented a system for running imSim on the UK computational grid and used it to perform parts of the image simulation runs in Europe.
%
SP contributed to the validation of various DC2 data products, and managed the Apache Spark tools at NERSC.
%
AP contributed to many aspects of the underlying extragalactic catalog and performed initial studies of using imSim in containers.
%
ESR contributed coverage mapping, processing QA for missing tracts, and galaxy color QA.
%
FJS participated in DC2 design phase, and production. Participated in catalog validation and matching between object and truth catalog.
%
SJS wrote the text for the photometric redshifts section.
%
TDU was involved in setting up the initial imSim simulations to scale them up  on thousands of nodes of Theta and supporting clusters at Argonne.
%i
ASV was responsible for early generation of instance catalogs, implementing the Parsl workflow for imSim on NERSC and ALCF resources, and helping in initial validation of these outputs.
%
CWW carried out early planning for DC2, worked on development, testing and management of the imSim image simulation program, and tested the released data product format.
%
MPW implemented the code to add lensed host galaxies to the lensed AGN and lensed SNe in the DC2 code.
%
MWV co-led the Data Access Task Force, served as the Data Coordinator, and contributed to validation of the DC2 data products.
%

%%%%%% References %%%%%% 
\clearpage
\phantomsection
\addcontentsline{toc}{section}{References}

\bibliographystyle{aasjournal}
\bibliography{ref}

\end{document}
